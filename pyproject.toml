[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
include = ["lambda_hat*"]

[tool.setuptools.package-data]
lambda_hat = ["conf/**/*.yaml"]

[project]
name = "lambda-hat"
version = "0.1.0"
description = "Lambda-Hat: Local Learning Coefficient (LLC) estimation via SGLD/HMC/MCLMC"
readme = "README.md"
requires-python = ">=3.11,<3.13"
dependencies = [
    "arviz~=0.22.0",
    "blackjax==1.2.5",
    "cookiecutter>=2.6.0",
    "equinox>=0.13.1",
    "flax>=0.12.0",
    "matplotlib>=3.7.0",
    "numpy>=1.24.0",
    "omegaconf>=2.3.0",
    "optax>=0.2.5",
    "optuna>=4.2.0",
    "pandas>=2.0.0",
    "parsl>=2024.11.18",
    "pyarrow>=14.0.0",
    "pyyaml>=6.0",
    "scipy>=1.11",
    "tensorboardx>=2.6.4",
]

[project.optional-dependencies]

# Local / macOS / CPU (MPS or CPU-only)
cpu = [
  "jax~=0.7.2",               # pulls CPU/MPS wheels from PyPI
]

# CUDA 12.x wheels for Linux (bundled CUDA libs; only needs a recent NVIDIA driver)
cuda12 = [
  "jax[cuda12_local]~=0.7.2"
]

# Normalizing flow VI (requires FlowJAX; Equinox is now in base deps)
flowvi = [
  "flowjax>=0.11.0",
]

[dependency-groups]
dev = [
    "files-to-prompt>=0.6",
    "marimo>=0.15.2",
    "pytest>=8.4.2",
    "ruff>=0.13.1",
]

[project.scripts]
lambda-hat-promote = "lambda_hat.entrypoints.promote:main"
lambda-hat-build-target = "lambda_hat.entrypoints.build_target:main"
lambda-hat-sample = "lambda_hat.entrypoints.sample:main"
lh = "lambda_hat.entrypoints.lh:main"
parsl-llc = "lambda_hat.entrypoints.parsl_llc:main"
parsl-optuna = "lambda_hat.entrypoints.parsl_optuna:main"

[tool.ruff]
line-length = 100
target-version = "py312"

[tool.ruff.lint]
extend-select = ["E","F","I"]
ignore = []

[tool.ruff.format]
quote-style = "double"
